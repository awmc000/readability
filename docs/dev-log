# Day 1, august 5th 2023

Wrote first draft of requirements/specification. Trying to get IO and
hash table working. Tested basic functionality like insertion, true/
false "contains" check, printing contents. Test frame will need 
cleanup. Resizing needs to be implemented.

Found this regex to use for syllable counting by Matt Ke on Stack 
Overflow.

/([aeiouyAEIOUY]+[^e.\s])|([aiouyAEIOUY]+\b)|(\b[^aeiouy0-9.']+e\b)/mg

# Day 2, August 6th 2023

Further work on the hash table. Resize working great after switching 
from flexible array member to double pointer. Successfully loaded the
Dale list of "769" (actually, close to 1500) easy words into a hash
table using a regex to recognize where a word starts and ends. The 
regular expression was definitely overkill for a file where words are
separated by newlines without even hypens. isalpha() would have been
enough, but I wanted to test this regex too. It will be used to pull
words from lines of text given by the user.

Lorge's description of the Readability Index seems to call for a set.

	" Since the count is the number of differ-
	ent hard words, each hard word is
	counted only once. For instance, if in
	the passage 'reliability' occurred three
	times, it still would be counted only
	once. "

This makes me think of a set, but I could probably just modify the 
hash table to have a parameter that forces entries to be unique, 
rejecting strings that are already contained.

# Day 3, August 7th 2023

Successfully loading the Dale list into a hash table in `main.c`. It
seems that regex isn't the right solution for counting words and 
sentences. I should do it with simple char checking and counting.

Created the "io" module on this day.

# Day 4, August 9th 2023

Successfully counting words, sentences, easy words, and prepositions
in the test text file! Worked out some simple problems I had with
putting words in an array.

# Day 5, August 12th 2023

Got the text analysis in main.c to evaluate line by line rather than
trying to load the whole file into dynamic memory which wasn't 
working. I have been thinking about it for a few days though, and 
am thinking I needed to discard the Lorge formula completely. It's a
waste of time! Dale-Chall is much more computer friendly, and it's
what wordcounter uses anyways!

# Day 6, August 13th 2023

Finally figured out why the Dale Chall scores were giving 0. The ints
needed to be converted to doubles before being divided. Duh. Changed
the design doc to reflect the decision to use Dale Chall only.

Reorganized file dir. Need to learn to use Pikchr to make diagrams.
That could be really handy.

# Day 7, August 15th 2023 (retroactive)

On this day, I added the text grade description for the Dale Chall
score computed, and started trying to hunt down the print statement
that was printing every word in each text evaluated.

# Day 8, August 16th 2023

I am going to split all the Dale Chall stuff into its own module,
which I think I will call `scoring`. I also want to move the headers
and source files into their own folders and make sure the makefile
can handle that. Got that done with some trouble. I accidentally
`mv`ed one header into anothers name, losing the content of the 
header. Just pasted it back from git to fix that.

# Day 9, August 18th 2023

Added a function macro to test_utils module that will save some LOCs.

# Day 10, August 20th 2023 (retroactive)

On this day, I was working on the scoring problems. Right now, a huge
quantity of easy words are perceived as hard words, because they are
other forms of the word. "work" is on the list, "working", "works",
"worked" are not. 

I implemented the `drop_end_if_s()` function, but I don't think it is
going to be a permanent solution. English orthography just does not
follow hard and fast rules so that any word ending in "ed" can have
those letters stripped to get the root word.

# Day 11, August 21st 2023

https://github.com/gutfeeling/word_forms

I think this Python module will help me solve the problem easily. It
has a function to return all the forms of a given word, so I could
write a new, expanded list of all the forms of the words on the 
original list. It will be much larger, I don't know how much, maybe
roughly five times as many words (15,000 words) as a wild guess. This
would still use a tolerable amount of memory, although it definitely
makes the database usage more appealing.

# Days 12-13-14, August 23, 24, 25 2023

Have been working on memory leaks. Fixed the smallest one: the leak
of words in the word array. The worst leak is that for some reason
no strings are deleted successfully from the proper nouns list. 